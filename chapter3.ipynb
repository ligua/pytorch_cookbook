{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor and autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor,张量\n",
    "\n",
    "粗暴认为它是一个数组，支持高效的科学计算，和numpy中的ndarrays类似\n",
    "\n",
    "从接口API的角度，对tensor的操作分为两类\n",
    "- torch.function : torch.save \n",
    "- tensor.funciton: tensor.view\n",
    "\n",
    "从存储的角度，对tensor的操作分为两类\n",
    "- donnot change itself : a.add(b)\n",
    "- change itself, inplace : a.add_(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate one Tensor\n",
    "- Tensor(*size) \n",
    "- ones\n",
    "- zeros\n",
    "- eye\n",
    "- arange(s, e, step)\n",
    "- rand / randn : random or 标准分布\n",
    "- normal(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        nan  4.5916e-41  0.0000e+00\n",
       " 0.0000e+00  1.8401e+37  0.0000e+00\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  2  3\n",
       " 4  5  6\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.tolist() # change Tensor to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numel() # b number of elements in b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " 1.00000e-45 *\n",
       "   1.4013  0.0000  1.4013\n",
       "   0.0000  1.4013  0.0000\n",
       " [torch.FloatTensor of size 2x3], \n",
       "  2\n",
       "  3\n",
       " [torch.FloatTensor of size 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.Tensor(b.size()) # c with the same size as b\n",
    "d = torch.Tensor((2,3))\n",
    "c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape # same as b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0\n",
       " 0  0  0\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 3\n",
       " 5\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1.0000\n",
       "  5.5000\n",
       " 10.0000\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.0035  0.9841 -0.4429\n",
       " 0.6638 -0.4723 -0.2171\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2333  0.3416  0.4226\n",
       " 0.6209  0.7170  0.6326\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4\n",
       " 0\n",
       " 2\n",
       " 1\n",
       " 3\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(5) # random sorting for 5 element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0\n",
       " 0  1  0\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0\n",
       " 0  1  0\n",
       " 0  0  1\n",
       " 0  0  0\n",
       "[torch.FloatTensor of size 4x3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的Tensor操作\n",
    "\n",
    "- tensor.view : 改变tensor的形状，返回的新tensor和原来的tensor共享内存， 并不会修改自身的数据\n",
    "- squeeze or unsqueeze : 添加维度或者减少维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 3  4  5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6)\n",
    "a.view(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1\n",
       " 2  3\n",
       " 4  5\n",
       "[torch.FloatTensor of size 3x2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(-1, 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0  1\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  3\n",
       "\n",
       "(2 ,.,.) = \n",
       "  4  5\n",
       "[torch.FloatTensor of size 3x1x2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0  1\n",
       "\n",
       "(1 ,.,.) = \n",
       "  2  3\n",
       "\n",
       "(2 ,.,.) = \n",
       "  4  5\n",
       "[torch.FloatTensor of size 3x1x2]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,0 ,.,.) = \n",
       "  0  1  2\n",
       "  3  4  5\n",
       "[torch.FloatTensor of size 1x1x2x3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.view(1,1,1,2,3)\n",
    "c.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 3  4  5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze() # squeeze all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0  100\n",
       "   2    3\n",
       "   4    5\n",
       "[torch.FloatTensor of size 3x2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] = 100\n",
    "b\n",
    "# share memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0  100    2\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0.0000  100.0000    2.0000\n",
       "   3.0000    4.0000    5.0000\n",
       "   0.0000    0.0000    0.0000\n",
       "[torch.FloatTensor of size 3x3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.resize_(3,3) # generate new memory space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903  0.0037 -1.6036  0.6245\n",
       "-1.8013  0.2796 -1.0926  0.1169\n",
       " 0.6609  0.5842  0.9660  0.5513\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903\n",
       " 0.0037\n",
       "-1.6036\n",
       " 0.6245\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903\n",
       "-1.8013\n",
       " 0.6609\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6035573482513428"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6244868040084839"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903  0.0037 -1.6036  0.6245\n",
       "-1.8013  0.2796 -1.0926  0.1169\n",
       "[torch.FloatTensor of size 2x4]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.ByteTensor of size 3x4]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  0  0  1\n",
       " 0  1  0  0\n",
       " 1  1  1  1\n",
       "[torch.ByteTensor of size 3x4]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903\n",
       " 0.6245\n",
       " 0.2796\n",
       " 0.6609\n",
       " 0.5842\n",
       " 0.9660\n",
       " 0.5513\n",
       "[torch.FloatTensor of size 7]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[a>0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.7903  0.0037 -1.6036  0.6245\n",
       "-1.8013  0.2796 -1.0926  0.1169\n",
       "[torch.FloatTensor of size 2x4]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[torch.LongTensor([0, 1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.arange(0, 16).view(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3\n",
       "  4   5   6   7\n",
       "  8   9  10  11\n",
       " 12  13  14  15\n",
       "[torch.FloatTensor of size 4x4]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3\n",
       "  4   5   6   7\n",
       "  8   9  10  11\n",
       " 12  13  14  15\n",
       "[torch.FloatTensor of size 4x4]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 16).view(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = torch.LongTensor([[0,1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   5  10  15\n",
       "[torch.FloatTensor of size 1x4]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对角线的元素\n",
    "index = torch.LongTensor([[0,1,2,3]])\n",
    "a.gather(0, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  3\n",
       "  6\n",
       "  9\n",
       " 12\n",
       "[torch.FloatTensor of size 4x1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取反对角线上的元素\n",
    "index = torch.LongTensor([[3,2,1,0]]).t()\n",
    "a.gather(1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 12   9   6   3\n",
       "[torch.FloatTensor of size 1x4]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取反对角线上的元素\n",
    "index = torch.LongTensor([[3,2,1,0]])\n",
    "a.gather(0, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   5  10  15\n",
       " 12   9   6   3\n",
       "[torch.FloatTensor of size 2x4]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取两个对角线上的元素\n",
    "index = torch.LongTensor([[0,1,2,3],[3,2,1,0]])\n",
    "a.gather(0, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   3\n",
       "  5   6\n",
       " 10   9\n",
       " 15  12\n",
       "[torch.FloatTensor of size 4x2]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取两个对角线上的元素\n",
    "index = torch.LongTensor([[0,1,2,3],[3,2,1,0]]).t()\n",
    "a.gather(1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected index [4 x 2] to be smaller size than src [3 x 3] and to be smaller than tensor [4 x 4] apart from dimension 1 at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\lib\\th\\generic/THTensorMath.c:593",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-a6b743cb4525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected index [4 x 2] to be smaller size than src [3 x 3] and to be smaller than tensor [4 x 4] apart from dimension 1 at c:\\anaconda2\\conda-bld\\pytorch_1519496000060\\work\\torch\\lib\\th\\generic/THTensorMath.c:593"
     ]
    }
   ],
   "source": [
    "c = torch.zeros(4,4)\n",
    "c.scatter_(1, index, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy风格的高级索引机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.arange(0, 27).view(3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 24.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1,2], x[2,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 14\n",
       " 24\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[1,2],[1,2],[2,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 19\n",
       " 10\n",
       "  1\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[[2,1,0], [0], [1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor的类型\n",
    "- torch.FloatTensor\n",
    "- torch.DoubleTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-45 *\n",
       "  0.0000  0.0000  4.2039\n",
       "  0.0000  1.4013  0.0000\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = a.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  0  0\n",
       " 0  0  0\n",
       "[torch.IntTensor of size 2x3]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐元素操作\n",
    "输出和输入的形状相同\n",
    "- abs/sqrt/div/exp/fmod/log\n",
    "- cos/sin/asin/atan2/cosh\n",
    "- ceil/round/floor/cosh\n",
    "- clamp\n",
    "- sigmoid/tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1.0000  0.5403 -0.4161\n",
       "-0.9900 -0.6536  0.2837\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6).view(2,3)\n",
    "torch.cos(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 3  4  5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 0  1  2\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 0  1  2\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.fmod(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   4\n",
       "  9  16  25\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   4\n",
       "  9  16  25\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归并操作\n",
    "- mean/sum/median/mode\n",
    "- norm/dist\n",
    "- std/var\n",
    "- cumsum/cumprod 累加/累乘\n",
    "\n",
    "使得输出形状小于输入形状，并按照某一个维度进行指定的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于dim参数，加入输入的形状为(m, n, k)\n",
    "- dim is 0, output size is (1,n,k) or (n,k)\n",
    "- dim is 1, output size is (m,1,k) or (m,k)\n",
    "- dim is 2, output size is (m,n,k) or (m,n)\n",
    "\n",
    "关于keepdim，为True则保留1的维度，默认不保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.ones(2, 3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2  2  2\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 2\n",
       " 2\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=0, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 3\n",
       " 3\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0  1  2\n",
       " 3  4  5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6).view(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   3\n",
       "  3   7  12\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cumsum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   4\n",
       "  9  16  25\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较操作\n",
    "- gt/lt/ge/le/eq/ne\n",
    "- topk\n",
    "- sort\n",
    "- max/min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   3   6\n",
       "  9  12  15\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.linspace(0, 15, 6).view(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 15  12   9\n",
       "  6   3   0\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.linspace(15, 0, 6).view(2,3)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  15\n",
       "   6\n",
       " [torch.FloatTensor of size 2], \n",
       "  0\n",
       "  0\n",
       " [torch.LongTensor of size 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(b, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两个返回值，第一行和第二行的最大值，最大值分别是这一行的第几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 10  10  10\n",
       " 10  12  15\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(a, min=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性代数\n",
    "\n",
    "|name|func|\n",
    "| --------   | -----:   | :----: |\n",
    "|trace|对角线元素之和|\n",
    "\n",
    "|diag\n",
    "- triu\n",
    "- mm/bmm\n",
    "- addmm/addbmm/addmv\n",
    "- t\n",
    "- dot/cross\n",
    "- inverse\n",
    "- svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor和numpy之间进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones([2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.DoubleTensor of size 2x3]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1  1\n",
       " 1  1  1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0, 1] = 100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   1  100    1\n",
       "   1    1    1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0, 1] = 100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 100.,   1.],\n",
       "       [  1.,   1.,   1.]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.numpy()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   1  200    1\n",
       "   1    1    1\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b and c share memory\n",
    "c[0, 1] = 200\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor的内部结构\n",
    "分为信息区Tensor和存储区Storage\n",
    "- Tensor:size, stride, type\n",
    "- Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0\n",
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0, 6)\n",
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0\n",
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.view(2, 3)\n",
    "b.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the id of the object is the memory address of this object\n",
    "id(b.storage()) == id(a.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0  100    2\n",
       "   3    4    5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1] = 100\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0\n",
       " 100.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a[2:]\n",
    "c.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086690127048"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086690127040"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data_ptr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_ptr()会返回tensor首元素的内存地址，相差8是因为2个float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0\n",
       " 100\n",
       "-100\n",
       "   3\n",
       "   4\n",
       "   5\n",
       "[torch.FloatTensor of size 6]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0] = -100\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-100\n",
       "   3\n",
       "   4\n",
       "   5\n",
       "[torch.FloatTensor of size 4]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.Tensor(c.storage())\n",
    "d[0] = 6666\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 6666   100  -100\n",
       "    3     4     5\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到下面的几个tensor都是共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a.storage()) == id(b.storage()) == id(c.storage()) == id(d.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage_offset(), b.storage_offset(), c.storage_offset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "绝大多操作并不修改storage信息，而是改变tensor的头部信息，节省内存，并且提升了处理速度。\n",
    "\n",
    "一般高级索引都不和原来的tensor共享内存，但是普通索引则可以。\n",
    "\n",
    "即numpy风格的高级索引。\n",
    "\n",
    "因为普通索引可以通过修改tensor头部信息（offset，stride，size）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor持久化\n",
    "\n",
    "torch.save\n",
    "\n",
    "torch.load\n",
    "\n",
    "load时可以将GPU tenosr指定映射到CPU或者GPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(a, 'a.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a, b is GPU 0\n",
    "b = torch.load('a.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load a, c is CPU\n",
    "c = torch.load('a.pth', map_location=lambda storage, loc : storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 6666\n",
       "  100\n",
       " -100\n",
       "    3\n",
       "    4\n",
       "    5\n",
       "[torch.cuda.FloatTensor of size 6 (GPU 0)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor的向量化\n",
    "\n",
    "向量化计算是一种特殊的并行化计算方式。\n",
    "\n",
    "一般程序在同一个时间只会执行一个操作，\n",
    "\n",
    "向量化计算能够在同一时间执行多个操作，通常是对不同的数据执行同样的一个或者一批指令，即将指令应用在一个数组/向量上。\n",
    "\n",
    "常见即是避免使用for循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def for_loop_add(x, y):\n",
    "    result = []\n",
    "    for i, j in zip(x, y):\n",
    "        result.append(i+j)\n",
    "    return torch.Tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 µs ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "The slowest run took 15.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "8.12 µs ± 9.26 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(100)\n",
    "y = torch.zeros(100)\n",
    "%timeit -n 10 for_loop_add(x, y)\n",
    "%timeit -n 10 x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到有超过10倍的差异，实际使用中要尽量使用内建函数（builtin-function），函数由底层的C/C++实现，经由底层优化实现高效计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torch.set_num_threads设置多线程并行计算时所占用的线程数，从而限制所占用的CPU数目。\n",
    "\n",
    "使用 torch.set_printoptions来设置打印tensor时的数值精度和格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2ce94c88ba8>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2cebd6d5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "# set random seed\n",
    "# to confirm same result in different computers\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "\n",
    "def get_fake_data(batch_size=8):\n",
    "    ''' random data y = x * 2 + 3 '''\n",
    "    x = torch.rand(batch_size, 1)*20\n",
    "    y = x * 2 + (1 + torch.randn(batch_size, 1))*3\n",
    "    return x, y\n",
    "\n",
    "x, y = get_fake_data()\n",
    "\n",
    "plt.scatter(x.squeeze().numpy(), y.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init parameters\n",
    "w = torch.rand(1, 1)\n",
    "b = torch.zeros(1,1)\n",
    "lr = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ce94d81dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0116281509399414 3.018310308456421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ii in range(20000):\n",
    "    x, y = get_fake_data()\n",
    "\n",
    "    # forward\n",
    "    y_pred = x.mm(w) + b.expand_as(y)\n",
    "    loss = 0.5 * (y_pred - y) ** 2\n",
    "    loss = loss.sum()\n",
    "\n",
    "    # backward\n",
    "    dloss = 1\n",
    "    dy_pred = dloss * (y_pred - y)\n",
    "    dw = x.t().mm(dy_pred)\n",
    "    db = dy_pred.sum()\n",
    "\n",
    "    # update parameters\n",
    "    w.sub_(lr * dw)\n",
    "    b.sub_(lr * db)\n",
    "\n",
    "    if ii % 1000 == 0:\n",
    "        # draw\n",
    "        display.clear_output(wait=True)\n",
    "        x = torch.arange(0, 20).view(-1, 1)\n",
    "        y = x.mm(w) + b.expand_as(x)\n",
    "        plt.plot(x.numpy(), y.numpy()) # predicted\n",
    "\n",
    "        x2, y2 = get_fake_data(batch_size=20)\n",
    "        plt.scatter(x2.numpy(), y2.numpy()) # true data\n",
    "\n",
    "        plt.xlim(0, 20)\n",
    "        plt.ylim(0, 41)\n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "        \n",
    "        print(w.squeeze()[0], b.squeeze()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算图是现代深度学习框架的核心，为自动求导算法--反向传播（Back Propogation）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable\n",
    "Variable封装了tensor，并记录对tensor的操作记录来构建计算图，主要包含三个属性\n",
    "- data: variable所包含的tensor\n",
    "- grad: 保存data对应的梯度，grad也是variable，和data的形状一致\n",
    "- grad_fn: 指向一个Function，记录tensor的操作历史，即是什么操作的输出\n",
    "\n",
    "构造函数需要传入tensor，同时有两个参数可以选择。\n",
    "- requires_grad(bool):是否要对该Variable进行求导\n",
    "- volatile（bool):挥发，构建在这个variable上面的图都不会求导，专为推理阶段设计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算各个Variable的梯度，则只需要调用根节点variable的backward方法，autograd会自动沿着计算图反向传播，计算每一个叶子节点的梯度。\n",
    "\n",
    "variable.backward(grad_variables=None, retain_graph=None, create_graph=None)\n",
    "- grad_variable:\n",
    "- retain_graph:\n",
    "- create_graph:对反向传播过程再次构建计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Variable(torch.ones(3,4), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Variable(torch.zeros(3, 4))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 12\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c.sum()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       " 1  1  1  1\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否为叶子结点\n",
    "a.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    '''compute y'''\n",
    "    y = x ** 2 * torch.exp(x)\n",
    "    return y\n",
    "\n",
    "def gardf(x):\n",
    "    '''by hand'''\n",
    "    dx = 2*x*torch.exp(x) + x**2*torch.exp(x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5354  0.1078  8.1789  0.4551\n",
       " 1.0608  0.0260  2.5683  0.3988\n",
       " 0.4398  2.8664  0.1772  0.2013\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(3,4), requires_grad=True)\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " -0.0604  -0.4295  19.7654  -0.2569\n",
       "  4.0117  -0.2694   7.8032  -0.3343\n",
       " -0.2805   8.4989  -0.4604  -0.4608\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(torch.ones(y.size()))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " -0.0604  -0.4295  19.7654  -0.2569\n",
       "  4.0117  -0.2694   7.8032  -0.3343\n",
       " -0.2805   8.4989  -0.4604  -0.4608\n",
       "[torch.FloatTensor of size 3x4]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gardf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they are the same as showed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.ones(1))\n",
    "b = Variable(torch.rand(1), requires_grad = True)\n",
    "w = Variable(torch.rand(1), requires_grad = True)\n",
    "y = w * x\n",
    "z = y + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autograd会跟随用户的操作，记录生成当前variable的所有操作，并构建出一个有向无环图。每次进行一个操作，相应的计算图就会发生改变。链式法则，计算输入的各个Variable的梯度。每一个前向操作的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf, w.is_leaf, b.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.is_leaf, z.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward1 at 0x2ce9515d978>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward1 at 0x2ce9512d710>, 0), (<AccumulateGrad at 0x2ce9512d6a0>, 0))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions[0][0] == y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad_fn, x.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward1 at 0x2ce9512d710>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x2ce950b95c0>, 0), (None, 0))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MulBackward1' object has no attribute 'saved_variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-177-3ba15276330c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'MulBackward1' object has no attribute 'saved_variables'"
     ]
    }
   ],
   "source": [
    "y.grad_fn.saved_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向传播过程中非叶子结点的导师计算完之后即会被清空。\n",
    "- autograd.grad\n",
    "- hook\n",
    "\n",
    "实际使用的过程要避免修改grad的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(3), requires_grad=True)\n",
    "w = Variable(torch.ones(3), requires_grad=True)\n",
    "y = x * w\n",
    "# y 是依赖于w\n",
    "z = y.sum()\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 3], None)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()\n",
    "(x.grad, w.grad, y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一种方法：使用grad获取中间变量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       "  1\n",
       "  1\n",
       " [torch.FloatTensor of size 3],)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(3), requires_grad=True)\n",
    "w = Variable(torch.ones(3), requires_grad=True)\n",
    "y = x * w\n",
    "# y 是依赖于w\n",
    "z = y.sum()\n",
    "# z对y的梯度，隐式调用backward()\n",
    "torch.autograd.grad(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二种方法：使用hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y的梯度：\n",
      " Variable containing:\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hook是一个函数，输入为梯度\n",
    "def variable_hook(grad):\n",
    "    print('y的梯度：\\r\\n', grad)\n",
    "\n",
    "x = Variable(torch.ones(3), requires_grad=True)\n",
    "w = Variable(torch.ones(3), requires_grad=True)\n",
    "y = x * w\n",
    "# y 是依赖于w\n",
    "z = y.sum()\n",
    "# 注册hook\n",
    "hook_handle = y.register_hook(variable_hook)\n",
    "# BP\n",
    "z.backward()\n",
    "# 用完之后记得移除hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 4\n",
       " 6\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.arange(3), requires_grad=True)\n",
    "y = x ** 2 + x * 2\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2\n",
       " 4\n",
       " 6\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.arange(3), requires_grad=True)\n",
    "y = x ** 2 + x * 2\n",
    "z = y.sum()\n",
    "y_grad_variables = Variable(torch.Tensor([1,1,1])) # dz/dy\n",
    "y.backward(y_grad_variables) # 从y开始进行反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只有对variable的操作才能够使用autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 扩展autograd\n",
    "\n",
    "写一个function进行扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "class MultiplyAdd(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b):\n",
    "        print('type in forward ', type(x))\n",
    "        ctx.save_for_backward(w, x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w, x = ctx.saved_variables\n",
    "        print('type in backward ', type(x))\n",
    "        grad_w = grad_output * x\n",
    "        grad_x = grad_output * w\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type in backward start forward propagation <class 'torch.autograd.variable.Variable'>\n",
      "\n",
      "type in forward  <class 'torch.FloatTensor'>\n",
      "start back propagation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, Variable containing:\n",
       "  1\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  1\n",
       " [torch.FloatTensor of size 1])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(1))\n",
    "w = Variable(torch.rand(1), requires_grad=True)\n",
    "b = Variable(torch.rand(1), requires_grad=True)\n",
    "print('start forward propagation')\n",
    "z = MultiplyAdd.apply(w, x, b)\n",
    "print('start back propagation')\n",
    "z.backward()\n",
    "\n",
    "# show grad\n",
    "x.grad, w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start forward propagation\n",
      "type in forward  <class 'torch.FloatTensor'>\n",
      "start back propagation\n",
      "type in backward  <class 'torch.autograd.variable.Variable'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  1\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  0.3917\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  1\n",
       " [torch.FloatTensor of size 1])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(1))\n",
    "w = Variable(torch.rand(1), requires_grad=True)\n",
    "b = Variable(torch.rand(1), requires_grad=True)\n",
    "print('start forward propagation')\n",
    "z = MultiplyAdd.apply(w, x, b)\n",
    "print('start back propagation')\n",
    "\n",
    "# 调用MultiplyAdd.backward\n",
    "# 输出grad_w, grad_x, grad_b\n",
    "z.grad_fn.apply(Variable(torch.ones(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forwad函数的输入为tensor，而backward函数的输入则是variable，为了实现高阶求导。backward函数的输入和返回值都是Variable。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  10\n",
       " [torch.FloatTensor of size 1],)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "y = x ** 2\n",
    "grad_x = torch.autograd.grad(y, x, create_graph=True)\n",
    "grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_grad_x = torch.autograd.grad(grad_x[0], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  2\n",
       " [torch.FloatTensor of size 1],)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_grad_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用这种方法实现Sigmoid的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        output = 1 / (1 + torch.exp(-x))\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output,  = ctx.saved_variables\n",
    "        grad_x = output + (1 - output) * grad_output\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "for output no. 0,\n numerical:(\n\nColumns 0 to 9 \n 0.2497  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.2490  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.2315  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0868  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.2270  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.1063  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2413  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0699  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2203  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1996\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n\nColumns 10 to 11 \n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.2377  0.0000\n 0.0000  0.1113\n[torch.FloatTensor of size 12x12]\n,)\nanalytical:(\n\nColumns 0 to 9 \n 1.0000  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167\n 0.5311  1.0000  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311\n 0.3640  0.3640  1.0000  0.3640  0.3640  0.3640  0.3640  0.3640  0.3640  0.3640\n 0.9041  0.9041  0.9041  1.0000  0.9041  0.9041  0.9041  0.9041  0.9041  0.9041\n 0.6515  0.6515  0.6515  0.6515  1.0000  0.6515  0.6515  0.6515  0.6515  0.6515\n 0.8791  0.8791  0.8791  0.8791  0.8791  1.0000  0.8791  0.8791  0.8791  0.8791\n 0.5933  0.5933  0.5933  0.5933  0.5933  0.5933  1.0000  0.5933  0.5933  0.5933\n 0.0756  0.0756  0.0756  0.0756  0.0756  0.0756  0.0756  1.0000  0.0756  0.0756\n 0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  1.0000  0.6724\n 0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  1.0000\n 0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889\n 0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725\n\nColumns 10 to 11 \n 0.5167  0.5167\n 0.5311  0.5311\n 0.3640  0.3640\n 0.9041  0.9041\n 0.6515  0.6515\n 0.8791  0.8791\n 0.5933  0.5933\n 0.0756  0.0756\n 0.6724  0.6724\n 0.7245  0.7245\n 1.0000  0.3889\n 0.8725  1.0000\n[torch.FloatTensor of size 12x12]\n,)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-7a7e18dc3cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 使用数值逼近的方法不断检验计算梯度的公式是否正确\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\gradcheck.py\u001b[0m in \u001b[0;36mgradcheck\u001b[1;34m(func, inputs, eps, atol, rtol, raise_exception)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalytical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0matol\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrtol\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfail_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'for output no. %d,\\n numerical:%s\\nanalytical:%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumerical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalytical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mreentrant\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\gradcheck.py\u001b[0m in \u001b[0;36mfail_test\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfail_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: for output no. 0,\n numerical:(\n\nColumns 0 to 9 \n 0.2497  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.2490  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.2315  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0868  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.2270  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.1063  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2413  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0699  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.2203  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1996\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000\n\nColumns 10 to 11 \n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.0000  0.0000\n 0.2377  0.0000\n 0.0000  0.1113\n[torch.FloatTensor of size 12x12]\n,)\nanalytical:(\n\nColumns 0 to 9 \n 1.0000  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167  0.5167\n 0.5311  1.0000  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311  0.5311\n 0.3640  0.3640  1.0000  0.3640  0.3640  0.3640  0.3640  0.3640  0.3640  0.3640\n 0.9041  0.9041  0.9041  1.0000  0.9041  0.9041  0.9041  0.9041  0.9041  0.9041\n 0.6515  0.6515  0.6515  0.6515  1.0000  0.6515  0.6515  0.6515  0.6515  0.6515\n 0.8791  0.8791  0.8791  0.8791  0.8791  1.0000  0.8791  0.8791  0.8791  0.8791\n 0.5933  0.5933  0.5933  0.5933  0.5933  0.5933  1.0000  0.5933  0.5933  0.5933\n 0.0756  0.0756  0.0756  0.0756  0.0756  0.0756  0.0756  1.0000  0.0756  0.0756\n 0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  0.6724  1.0000  0.6724\n 0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  0.7245  1.0000\n 0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889  0.3889\n 0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725  0.8725\n\nColumns 10 to 11 \n 0.5167  0.5167\n 0.5311  0.5311\n 0.3640  0.3640\n 0.9041  0.9041\n 0.6515  0.6515\n 0.8791  0.8791\n 0.5933  0.5933\n 0.0756  0.0756\n 0.6724  0.6724\n 0.7245  0.7245\n 1.0000  0.3889\n 0.8725  1.0000\n[torch.FloatTensor of size 12x12]\n,)\n"
     ]
    }
   ],
   "source": [
    "test_input = Variable(torch.randn(3,4), requires_grad=True)\n",
    "# 使用数值逼近的方法不断检验计算梯度的公式是否正确\n",
    "torch.autograd.gradcheck(Sigmoid.apply, (test_input, ), eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
